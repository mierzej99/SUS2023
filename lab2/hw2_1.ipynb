{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "1. Read details about the Iris data set here and here. What features are in the data set? What is the target (y) variable and what possible values does it take on?\n",
    "\n",
    "Ans: In the dataset there are four features: Sepal Length, Sepal Width, Petal Length and Petal Width. Target variable is class(Species) of Iris."
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1687936770.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  Cell \u001B[0;32mIn[1], line 1\u001B[0;36m\u001B[0m\n\u001B[0;31m    Read details about the Iris data set here and here. What features are in the data set? What\u001B[0m\n\u001B[0m         ^\u001B[0m\n\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m invalid syntax\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. Which features are we keeping for our training set (X)? How would you change the code to choose different features? When you finish this tutorial, come back and modify this code to see how it influences the results.\n",
    "\n",
    "Ans: We are keeping last two features of data - Petal Length and Petal Width.\n",
    "To change feature we have to change range of slicing in this commend: X = iris.data[:, 2:]. For example: X = iris.data[:, 1:3].\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "3. Read an explanation of Decision Trees and then look at the documentation for the function to see what parameters exist. What tips to they provide for practical use?\n",
    "\n",
    "Ans: Understand the parameters and tune them appropriately.\n",
    "Use cross-validation to evaluate the performance of the model on unseen data.\n",
    "Visualize the tree to better understand its behavior.\n",
    "Preprocess the data to ensure the model's robustness."
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3045854604.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;36m  Cell \u001B[1;32mIn[1], line 1\u001B[1;36m\u001B[0m\n\u001B[1;33m    3. Read an explanation of Decision Trees and then look at the documentation for the function\u001B[0m\n\u001B[1;37m       ^\u001B[0m\n\u001B[1;31mSyntaxError\u001B[0m\u001B[1;31m:\u001B[0m invalid syntax\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "4. What version of decision trees is implemented by scikit-learn? How does it relate to those discussed in class?\n",
    "\n",
    "\n",
    "Ans: scikit-learn uses an optimized version of the CART algorithm. CART algorithm support numerical target variables and does not compute rule sets based on trees."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "5. Note that information gain is not the default selection criteria. How do we change that. How does the default compare to information gain?\n",
    "\n",
    "Ans: To change selection criteria we have to add use parameter \"criterion\": tree_clf = DecisionTreeClassifier(criterion=\"entropy\", max_depth=2, random_state=42).\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "6. max_depth is set to 2. How does this related to our discussion about stopping criteria and overfitting? How do we prevent the use of max_depth. Can you find other parameters to prevent overfitting?\n",
    "\n",
    "Ans: max_dept is used to stop overfiting, if decision tree would be to deep there is high chance that it will perform poorly on unseen data. Other parameters to prevent overfitting are: min_samples_split, min_samples_leaf, min_weight_fraction_leaf, min_impurity_decrease, ccp_alpha.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "7. Try to use different selection criterion and max_depth and report which one is better?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(max_depth=2, random_state=42)\n",
      "0.9666666666666667 gini 2\n",
      "DecisionTreeClassifier(max_depth=3, random_state=42)\n",
      "0.9666666666666667 gini 3\n",
      "DecisionTreeClassifier(max_depth=4, random_state=42)\n",
      "0.9666666666666667 gini 4\n",
      "DecisionTreeClassifier(max_depth=5, random_state=42)\n",
      "0.9666666666666667 gini 5\n",
      "DecisionTreeClassifier(max_depth=6, random_state=42)\n",
      "0.9666666666666667 gini 6\n",
      "DecisionTreeClassifier(max_depth=7, random_state=42)\n",
      "0.9666666666666667 gini 7\n",
      "DecisionTreeClassifier(max_depth=8, random_state=42)\n",
      "0.9666666666666667 gini 8\n",
      "DecisionTreeClassifier(max_depth=9, random_state=42)\n",
      "0.9666666666666667 gini 9\n",
      "DecisionTreeClassifier(max_depth=10, random_state=42)\n",
      "0.9666666666666667 gini 10\n",
      "DecisionTreeClassifier(criterion='entropy', max_depth=2, random_state=42)\n",
      "0.9666666666666667 entropy 2\n",
      "DecisionTreeClassifier(criterion='entropy', max_depth=3, random_state=42)\n",
      "0.9666666666666667 entropy 3\n",
      "DecisionTreeClassifier(criterion='entropy', max_depth=4, random_state=42)\n",
      "0.9666666666666667 entropy 4\n",
      "DecisionTreeClassifier(criterion='entropy', max_depth=5, random_state=42)\n",
      "0.9666666666666667 entropy 5\n",
      "DecisionTreeClassifier(criterion='entropy', max_depth=6, random_state=42)\n",
      "0.9666666666666667 entropy 6\n",
      "DecisionTreeClassifier(criterion='entropy', max_depth=7, random_state=42)\n",
      "0.9666666666666667 entropy 7\n",
      "DecisionTreeClassifier(criterion='entropy', max_depth=8, random_state=42)\n",
      "0.9666666666666667 entropy 8\n",
      "DecisionTreeClassifier(criterion='entropy', max_depth=9, random_state=42)\n",
      "0.9666666666666667 entropy 9\n",
      "DecisionTreeClassifier(criterion='entropy', max_depth=10, random_state=42)\n",
      "0.9666666666666667 entropy 10\n",
      "DecisionTreeClassifier(criterion='log_loss', max_depth=2, random_state=42)\n",
      "0.9666666666666667 log_loss 2\n",
      "DecisionTreeClassifier(criterion='log_loss', max_depth=3, random_state=42)\n",
      "0.9666666666666667 log_loss 3\n",
      "DecisionTreeClassifier(criterion='log_loss', max_depth=4, random_state=42)\n",
      "0.9666666666666667 log_loss 4\n",
      "DecisionTreeClassifier(criterion='log_loss', max_depth=5, random_state=42)\n",
      "0.9666666666666667 log_loss 5\n",
      "DecisionTreeClassifier(criterion='log_loss', max_depth=6, random_state=42)\n",
      "0.9666666666666667 log_loss 6\n",
      "DecisionTreeClassifier(criterion='log_loss', max_depth=7, random_state=42)\n",
      "0.9666666666666667 log_loss 7\n",
      "DecisionTreeClassifier(criterion='log_loss', max_depth=8, random_state=42)\n",
      "0.9666666666666667 log_loss 8\n",
      "DecisionTreeClassifier(criterion='log_loss', max_depth=9, random_state=42)\n",
      "0.9666666666666667 log_loss 9\n",
      "DecisionTreeClassifier(criterion='log_loss', max_depth=10, random_state=42)\n",
      "0.9666666666666667 log_loss 10\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    iris.data[:,2:], iris.target, test_size=0.4, random_state=4)\n",
    "\n",
    "\n",
    "criterions = [\"gini\", \"entropy\", \"log_loss\"]\n",
    "max_depth = [i for i in range(2,11)]\n",
    "\n",
    "for cri in criterions:\n",
    "    for max_dep in max_depth:\n",
    "        tree_clf = DecisionTreeClassifier(criterion=cri, max_depth=max_dep, random_state=42)\n",
    "        print(tree_clf)\n",
    "        tree_clf.fit(X_train, y_train)\n",
    "        print(tree_clf.score(X_test, y_test), cri, max_dep)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "It looks like on iris dataset changing these parameters do not have high effect on outcome."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
